#-----------------------
# @author: Tony Ribeiro
# @created: 2019/03/20
# @updated: 2019/03/29
#
# @desc: PyLFIT benchmarks evaluation script
#
#-----------------------

import sys
sys.path.insert(0, 'src/')
sys.path.insert(0, 'src/algorithms')
sys.path.insert(0, 'src/objects')

from utils import eprint
from lf1t import LF1T
from gula import GULA
from lfkt import LFkT
from pride import PRIDE
from lust import LUST
from evaluation_benchmarks import evaluate_on_bn_benchmark, evaluate_on_bn_benchmark_with_NN

# 0: Constants
#--------------

# Number of tests for averaging scores
run_tests = 1

# Number of transition to be generated by NN for improving algorithm learning
# None => all missing state from training set
nb_artificial_transition = 100

# 1: Main
#------------
if __name__ == '__main__':
    # Learning algorithm, choose from: LF1T / GULA / PRIDE
    algorithm = GULA
    NN = False

    perfect_test = True
    partial_test = False
    small_dataset = False

    if not NN:

        # Benchmarks tests 100%
        #-----------------------

        if perfect_test:
            eprint("> Start benchmark evaluation: perfect test")

            # DBG
            eprint(">> pyboolnet")
            eprint(">> raf: ???")
            evaluate_on_bn_benchmark(algorithm, "pbnet_toy_raf")

            eprint(">> pbnet_toy_n3s1c1a: ???")
            evaluate_on_bn_benchmark(algorithm, "pbnet_toy_n3s1c1a")

            eprint(">> pbnet_toy_n3s1c1b: ???")
            evaluate_on_bn_benchmark(algorithm, "pbnet_toy_n3s1c1b")

            eprint(">> pbnet_toy_n6s1c2: ???")
            evaluate_on_bn_benchmark(algorithm, "pbnet_toy_n6s1c2")

            eprint(">> pbnet_toy_n7s3: ???")
            evaluate_on_bn_benchmark(algorithm, "pbnet_toy_n7s3")

            eprint(">> pbnet_toy_n12c5: ???")
            evaluate_on_bn_benchmark(algorithm, "pbnet_toy_n12c5")
            #exit()

            eprint(">> Repressilator: 3 variables, 2 values, 7 rules, 8 transitions")
            evaluate_on_bn_benchmark(algorithm, "repressilator")

            eprint(">> Mammalian: 10 variables, 2 values, 50 rules, 1024 transitions")
            evaluate_on_bn_benchmark(algorithm, "mammalian")

            eprint(">> Fission: 10 variables, 2 values, 65 rules, 1024 transitions")
            evaluate_on_bn_benchmark(algorithm, "fission")

            eprint(">> Budding: 12 variables, 2 values, 124 rules, 4096 transitions")
            evaluate_on_bn_benchmark(algorithm, "budding")

            eprint(">> Arabidopsis: 15 variables, 2 values, 62 rules, 32768 transitions")
            evaluate_on_bn_benchmark(algorithm, "arabidopsis")

        # Benchmarks tests 100% - 10%
        #----------------------------

        if partial_test:
            eprint("> Start benchmark evaluation: partial test")

            accuracy_evolution = []

            for i in reversed(range(10,110,10)):

                accuracy = []

                eprint("\n> Benchmarks test with " + str(i) + "% training transitions")
                train_size = i / 100.0

                eprint(">> Repressilator: 3 variables, 2 values, 7 rules, 8 transitions")
                accuracy.append(evaluate_on_bn_benchmark(algorithm, "repressilator", train_size))

                eprint("\n>> Mammalian: 10 variables, 2 values, 50 rules, 1024 transitions")
                accuracy.append(evaluate_on_bn_benchmark(algorithm, "mammalian", train_size))

                eprint("\n>> Fission: 10 variables, 2 values, 65 rules, 1024 transitions")
                accuracy.append(evaluate_on_bn_benchmark(algorithm, "fission", train_size))

                eprint("\n>> Budding: 12 variables, 2 values, 124 rules, 4096 transitions")
                accuracy.append(evaluate_on_bn_benchmark(algorithm, "budding", train_size))

                eprint("\n>> Arabidopsis: 15 variables, 2 values, 62 rules, 32768 transitions")
                accuracy.append(evaluate_on_bn_benchmark(algorithm, "arabidopsis", train_size))

                accuracy_evolution.append(accuracy)

            train_size = 100
            for i in range(len(accuracy_evolution)):
                eprint(str(train_size) + ": " + str(accuracy_evolution[i]))
                train_size -= 10

            accuracy_evolution = []

        # Benchmarks tests 5 - 50 transitions
        #-------------------------------------

        if small_dataset:
            eprint("> Start benchmark evaluation: small dataset test")

            accuracy_evolution = []

            for i in reversed(range(5,55,5)):

                accuracy = []
                train_size = i

                eprint("\n> Benchmarks test with " + str(train_size) + " training transitions")

                eprint("\n>> Repressilator: 3 variables, 2 values, 7 rules, 8 transitions")
                accuracy.append(evaluate_on_bn_benchmark(algorithm, "repressilator", train_size))

                eprint("\n>> Mammalian: 10 variables, 2 values, 50 rules, 1024 transitions")
                accuracy.append(evaluate_on_bn_benchmark(algorithm, "mammalian", train_size))

                eprint("\n>> Fission: 10 variables, 2 values, 65 rules, 1024 transitions")
                accuracy.append(evaluate_on_bn_benchmark(algorithm, "fission", train_size))

                eprint("\n>> Budding: 12 variables, 2 values, 124 rules, 4096 transitions")
                accuracy.append(evaluate_on_bn_benchmark(algorithm, "budding", train_size))

                eprint("\n>> Arabidopsis: 15 variables, 2 values, 62 rules, 32768 transitions")
                accuracy.append(evaluate_on_bn_benchmark(algorithm, "arabidopsis", train_size))

                accuracy_evolution.append(accuracy)

            train_size = 50
            for i in range(len(accuracy_evolution)):
                eprint(str(train_size) + ": " + str(accuracy_evolution[i]))
                train_size -= 5

    # NN Tests
    #-----------------------
    if NN:

        # Benchmarks tests 100% - 10%
        #----------------------------

        if partial_test:
            eprint("> Start NN benchmark evaluation: partial test")

            accuracy_evolution = []

            for i in reversed(range(10,110,10)):

                accuracy = []

                eprint("\n> Benchmarks test with " + str(i) + "% training transitions")
                train_size = i / 100.0

                eprint("\n>> Mammalian: 10 variables, 2 values, 50 rules, 1024 transitions")
                accuracy.append(evaluate_on_bn_benchmark_with_NN(algorithm, "mammalian", train_size, nb_artificial_transition))

                eprint("\n>> Fission: 10 variables, 2 values, 65 rules, 1024 transitions")
                accuracy.append(evaluate_on_bn_benchmark_with_NN(algorithm, "fission", train_size, nb_artificial_transition))

                eprint("\n>> Budding: 12 variables, 2 values, 124 rules, 4096 transitions")
                accuracy.append(evaluate_on_bn_benchmark_with_NN(algorithm, "budding", train_size, nb_artificial_transition))

                eprint("\n>> Arabidopsis: 15 variables, 2 values, 62 rules, 32768 transitions")
                accuracy.append(evaluate_on_bn_benchmark_with_NN(algorithm, "arabidopsis", train_size, nb_artificial_transition))

                accuracy_evolution.append(accuracy)

            train_size = 100
            for i in range(len(accuracy_evolution)):
                eprint(str(train_size) + ": " + str(accuracy_evolution[i]))
                train_size -= 10

            accuracy_evolution = []

        # Benchmarks tests 100% - 10%
        #----------------------------

        if small_dataset:
            eprint("> Start NN benchmark evaluation: small datatest")

            accuracy_evolution = []

            for i in reversed(range(5,55,5)):

                accuracy = []

                eprint("\n> Benchmarks test with " + str(i) + " training transitions")
                train_size = i

                eprint("\n>> Mammalian: 10 variables, 2 values, 50 rules, 1024 transitions")
                accuracy.append(evaluate_on_bn_benchmark_with_NN(algorithm, "mammalian", train_size, nb_artificial_transition))

                eprint("\n>> Fission: 10 variables, 2 values, 65 rules, 1024 transitions")
                accuracy.append(evaluate_on_bn_benchmark_with_NN(algorithm, "fission", train_size, nb_artificial_transition))

                eprint("\n>> Budding: 12 variables, 2 values, 124 rules, 4096 transitions")
                accuracy.append(evaluate_on_bn_benchmark_with_NN(algorithm, "budding", train_size, nb_artificial_transition))

                eprint("\n>> Arabidopsis: 15 variables, 2 values, 62 rules, 32768 transitions")
                accuracy.append(evaluate_on_bn_benchmark_with_NN(algorithm, "arabidopsis", train_size, nb_artificial_transition))

                accuracy_evolution.append(accuracy)

            train_size = 50
            for i in range(len(accuracy_evolution)):
                eprint(str(train_size) + ": " + str(accuracy_evolution[i]))
                train_size -= 5

            accuracy_evolution = []
